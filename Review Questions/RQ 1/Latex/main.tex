\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}

\title{Review Questions 1 - ID2221}
\author{Emil Ståhl and Selam Fsha}
\date{September 2021}

\begin{document}
\input{frontpage}

\maketitle

\section{1. Explain how a file region can be left in an undefined state in GFS?}

A file region is consistent if all clients will always see the same data, regardless of which replicas they read from. The state of a file region depends on the success of an operation and whether there are concurrent mutations or not. Undefined state can occur as follows:

\subsection*{\textbf{Failure:}}

If an append operation fails at any replica server, the GFS client will retry the operation causing the replicas holding the same chunk to contain different data due to duplicates of a record. This can occur without having concurrent writes, simply as a result of a failed write which can occur due to a time out. The failed write that caused a duplicate record can also cause an undefined region. The undefined file region state can occur if a replica fails to recognize a mutation of a chunk, leading to that the replica does not perform the operation. When the client later retries to perform the append operation, the client that failed the last operation will have to pad the missing data in order for the new data / record to be written at the correct offset. This causes the replica to have padding written in a region where other replicas have the previously written data. Inconsistency causes an undefined file state. 

\subsection*{\textbf{Concurrent successes}}

As described above, a failed write can cause a file region to be inconsistent, hence undefined. But successful concurrent writes can cause consistent but undefined file regions. This can occur if the GFS client writes a very large chunk since it then breaks the chunk down into multiple write operations. This can lead to that the write operations are being interleaved or overwritten by concurrent operations from other GFS clients. This means a file region can contain fragments from other clients, however, all replicas containing the chunk will hold identical data due to that the primary node enforces one update order on all replicas. This results in a consistent but undefined file region state. 

Failure is a fundamental problem of distributed systems. When a failure occurs the sender may not know if the recipient received the message or not. This is why distributed systems guarantee that a message is delivered at least once or at most once. In this case, it appears GFS decided upon at least once delivery to the storage nodes which led to undefined and inconsistency are possible states for a file region. 


\section{Briefly explain the read operation in GFS? What’s the role of the primary node?}

\textbf{Read Operation:}

\begin{itemize}
    \item Application initiates  the read request. Application sends the read request to the GFS client with the file name the application wants to read.
\item The GFS client translates the request and sends it to the master node. The GFS client translates the request to GFS language and sends it to the master with the filename and chunk index.
\item The master responds with chunk handles and replica locations. The master sends a handler for the chunk that the GFS client needs and the replica locations. 
\item The client picks the most optimal location and sends the request (GFS client chooses one of the chunk servers based on the closest or less load and sends the request directly to that server with the chunk handler).
\item The chunkserver or servers send requested data to the client.
\item The client forwards the data to the application
\item The application can use that data.
\end{itemize}

\subsection*{\textbf{Role of primary node:}}

When an application requests to modify a chunk, there needs to be a so-called primary node that defines the update order. The master  node finds the set of chunk servers that have the desired chunk and grants a so-called chunk lease to one of these chunk servers.  The chunk server that holds the chunk lease is defined as the primary node, the other chunk servers are defined as secondaries. There can only be one primary for each chunk. The role of the primary node is to determine the serialization (update) order for all of the chunk’s modifications, and the secondaries must follow that order to ensure correctness. It is the job of the primary to communicate the order to the secondaries. The primary node holds the chunk lease for a set period of time, approximately 60 seconds. After expiration, the master may grant the lease to another node. Master is also able to revoke lease to disable modifications when a file is being renamed. If master loses contact with the primary, it will grant the lease to another node once the  lease expires.  In short,  the  role of the primary node is to enforce one update order for all chunk servers holding a specific chunk. 

\section{Using one example, show that in the CAP theorem, if we have Consistency and Partition Tolerance, we cannot provide Availability at the same time.}

The CAP theorem is an important  theorem in distributed systems and databases. It states that it is impossible for a distributed system to have more than two out of the three following properties: 

\begin{itemize}
    \item Consistency - Every read receives the most recent write or an error
    \item Availability - Every request receives non-error response
    \item Partition tolerance - The systems continues to operate despite failures 
\end{itemize}

This means that if we have Consistency and Partition tolerance in our system, we cannot ensure Availability. However, it should be noted that in the absence of a network failure, when the distributed system is running normally, both availability and consistency can be satisfied. The theorem is often misunderstood as one has to choose two properties at all times, when in fact the choice between consistency and availability is only in case of a network failure. As an example we can take a hypothetical financial service, in the case of a network failure we can choose to fulfil either consistency or availability. Due to the nature of the industry when we try to read transactions or account balance information we want to have the latest write or return an error response. When the system results in error response or timeout errors(i.e fulfil consistency), it fails to meet the availability property. An example of the CAP theorem is when using BigTable, in case of a network failure it will only ensure consistency and not availability. 

\clearpage
\section{Explain how the consistent hashing works.}

Cassandra uses data partitioning when the size of an object exceeds the capacity of a single machine. To partition, Cassandra uses consistent hashing which determines on which node in the network the partitioned data should be placed, it works as follows: 
\\\\
The data and the node id are hashed using the same hash function which operates in the same ID space. The ID space is equivalent to the output range of our hash function. The partition on which we should put our data is given by the following hash function: 
\\\\
\textit{partition} = hash(\textit{d}) mod \textit{n} where \textit{d} corresponds to our data and n is the size of our ID space. 
\\\\
Let's assume a network of 5 nodes with the ID’s \{10, 20, 30, 40, 50, 60, 70, 80, 90, 100\}, when we hash the data “ID2221”  we get the partition 69, on which node should we put the partition? In consistent hashing with data partitioning, we put the partition on the node having the next ID that is higher than the partition. In this case, our partition 69 should be put on the node with the id of 70, since that’s the next node when moving in a clockwise orientation around the id space. 

\clearpage
\section{Explain the finding process of tablets in BigTable.}

In BigTable, tables are split into multiple tablets which are segments of the table split at certain row keys so that each tablet is a few hundred megabytes or a few gigabytes in size. The tablets can then be stored on a distributed system of servers. To find a given tablet, the following process is used: \\\\
BigTable uses a three-level hierarchy for keeping control of tablets. The first step that is performed is to read a file stored in Chubby, which is a Distributed lock manager used with BigTable to ensure there’s only one active master. The file stored in Chubby holds the location of the root tablet, this tablet is responsible for storing the locations of the complete set of tablets existing in the system. The root tablet stores this information in a special metadata table. There are different levels of metadata tables, the root tablet uses its metadata tablet to point to other metadata tablets. Here, in the second level of metadata tablets, does BigTable store the locations of every tablet present in the system. The location of a regular user tablet is stored under a single row in the metadata tablet. These tablets are put together to form a complete table in the database. Lastly, to minimize requests and latency, the client using BigTable caches these tablet locations for future use. 

\subsection*{\textbf{Summary:}}

Chubby file $\rightarrow$ Root tablet $\rightarrow$ Metadata tablet $\rightarrow$ user table 


\end{document}
